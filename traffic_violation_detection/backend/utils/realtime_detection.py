import cv2
import numpy as np
from ultralytics import YOLO
import easyocr
from typing import Tuple, List, Dict, Optional
import logging
import threading
from queue import Queue
import time

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class RealtimeDetector:
    """Optimized real-time vehicle & license plate detection"""
    
    def __init__(self, model_path: str = 'yolov8n.pt', use_gpu: bool = False):
        """Initialize with optimizations for real-time processing"""
        # Initialize all attributes first to ensure they always exist
        self.model = None
        self.reader = None
        self.frame_skip = 2  # Process every 2nd frame
        self.frame_count = 0
        self.conf_threshold = 0.5
        
        try:
            # Load YOLO model
            self.model = YOLO(model_path)
            self.device = 'cuda' if use_gpu else 'cpu'
            logger.info(f"‚úì YOLO model loaded on {self.device}")
            
            # Initialize OCR
            self.reader = easyocr.Reader(['en'], gpu=use_gpu, verbose=False)
            logger.info(f"‚úì OCR reader initialized on {self.device}")
            
        except Exception as e:
            logger.error(f"Initialization error: {e}")
            self.model = None
            self.reader = None
    
    def detect_vehicles_realtime(self, frame: np.ndarray, skip: bool = True) -> List[Dict]:
        """
        Detect vehicles with frame skipping for speed
        """
        self.frame_count += 1
        
        # Skip frames for faster processing
        if skip and self.frame_count % self.frame_skip != 0:
            return []
        
        if self.model is None:
            return []
        
        try:
            # Run inference
            results = self.model(frame, conf=self.conf_threshold, verbose=False)
            detections = []
            
            for result in results:
                if result.boxes is not None:
                    for box in result.boxes:
                        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                        conf = float(box.conf[0])
                        cls = int(box.cls[0])
                        
                        # Car=2, Bus=5, Truck=7
                        if cls in [2, 5, 7]:
                            detections.append({
                                'bbox': (int(x1), int(y1), int(x2), int(y2)),
                                'conf': conf,
                                'class': cls,
                                'area': (x2 - x1) * (y2 - y1)
                            })
            
            return sorted(detections, key=lambda x: x['conf'], reverse=True)
        
        except Exception as e:
            logger.error(f"Detection error: {e}")
            return []
    
    def extract_plate_region(self, frame: np.ndarray, vehicle_bbox: Tuple) -> np.ndarray:
        """Extract license plate region from vehicle (lower 1/3)"""
        x1, y1, x2, y2 = vehicle_bbox
        height = y2 - y1
        
        # License plate usually in lower part
        plate_y1 = int(y1 + height * 0.6)
        plate_y2 = y2
        
        plate_region = frame[plate_y1:plate_y2, x1:x2]
        return plate_region if plate_region.size > 0 else None
    
    def recognize_plate_fast(self, plate_image: np.ndarray) -> Dict:
        """Fast OCR recognition with preprocessing"""
        if self.reader is None or plate_image is None or plate_image.size == 0:
            return {'text': '', 'conf': 0.0}
        
        try:
            # Preprocess
            gray = cv2.cvtColor(plate_image, cv2.COLOR_BGR2GRAY)
            _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)
            
            # Run OCR
            results = self.reader.readtext(thresh, detail=0)
            
            if not results:
                return {'text': '', 'conf': 0.0}
            
            text = ''.join(results).strip()
            return {'text': text, 'conf': 0.85}  # Simplified confidence
        
        except Exception as e:
            logger.error(f"OCR error: {e}")
            return {'text': '', 'conf': 0.0}
    
    def detect_traffic_light(self, frame: np.ndarray) -> Dict:
        """
        Detect traffic light status in frame
        Returns: {'status': 'red'|'green'|'yellow'|'unknown', 'confidence': float, 'location': (x,y,w,h)}
        """
        try:
            hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
            
            # Red light detection (both hues due to wrap-around)
            lower_red1 = np.array([0, 100, 100])
            upper_red1 = np.array([10, 255, 255])
            lower_red2 = np.array([170, 100, 100])
            upper_red2 = np.array([180, 255, 255])
            
            mask_red = cv2.inRange(hsv, lower_red1, upper_red1) | cv2.inRange(hsv, lower_red2, upper_red2)
            red_pixels = cv2.countNonZero(mask_red)
            
            # Green light detection
            lower_green = np.array([40, 40, 40])
            upper_green = np.array([80, 255, 255])
            mask_green = cv2.inRange(hsv, lower_green, upper_green)
            green_pixels = cv2.countNonZero(mask_green)
            
            # Yellow light detection
            lower_yellow = np.array([20, 100, 100])
            upper_yellow = np.array([40, 255, 255])
            mask_yellow = cv2.inRange(hsv, lower_yellow, upper_yellow)
            yellow_pixels = cv2.countNonZero(mask_yellow)
            
            total_pixels = red_pixels + green_pixels + yellow_pixels
            
            if total_pixels < 100:  # Not enough light detected
                return {'status': 'unknown', 'confidence': 0.0}
            
            red_ratio = red_pixels / total_pixels
            green_ratio = green_pixels / total_pixels
            yellow_ratio = yellow_pixels / total_pixels
            
            # Determine status based on ratios
            if red_ratio > 0.6:
                return {'status': 'red', 'confidence': red_ratio}
            elif green_ratio > 0.6:
                return {'status': 'green', 'confidence': green_ratio}
            elif yellow_ratio > 0.4:
                return {'status': 'yellow', 'confidence': yellow_ratio}
            else:
                return {'status': 'unknown', 'confidence': max(red_ratio, green_ratio, yellow_ratio)}
        
        except Exception as e:
            logger.error(f"Traffic light detection error: {e}")
            return {'status': 'unknown', 'confidence': 0.0}
    
    def estimate_speed_simple(self, detections_prev: List[Dict], 
                            detections_curr: List[Dict], fps: float) -> Dict:
        """Estimate speed from bounding box movement"""
        if not detections_prev or not detections_curr:
            return {}
        
        speeds = {}
        for curr in detections_curr:
            # Find closest previous detection
            best_prev = None
            min_dist = float('inf')
            
            for prev in detections_prev:
                x1_p, y1_p, x2_p, y2_p = prev['bbox']
                x1_c, y1_c, x2_c, y2_c = curr['bbox']
                
                center_p = ((x1_p + x2_p) / 2, (y1_p + y2_p) / 2)
                center_c = ((x1_c + x2_c) / 2, (y1_c + y2_c) / 2)
                
                dist = np.sqrt((center_c[0] - center_p[0])**2 + 
                             (center_c[1] - center_p[1])**2)
                
                if dist < min_dist:
                    min_dist = dist
                    best_prev = prev
            
            if best_prev and min_dist < 100:  # Within reasonable distance
                # Rough speed estimation
                speed_km = (min_dist / 10) * fps * 3.6  # Simplified formula
                speeds[str(curr['bbox'])] = {
                    'speed': min(speed_km, 120),  # Cap at 120 km/h
                    'distance': min_dist
                }
        
        return speeds


class StreamingProcessor:
    """Stream-based video processing for real-time performance"""
    
    def __init__(self, detector: RealtimeDetector, speed_limit: float = 60):
        self.detector = detector
        self.speed_limit = speed_limit
        self.violations = []
        self.detections_prev = []
        self.processing = False
        self.traffic_light_status = None
        self.red_light_frame_start = None
        
    def process_stream(self, video_source, 
                      output_callback=None, 
                      frame_callback=None) -> Dict:
        """
        Process video stream with real-time updates
        Detects: speeding, red light running, parking violations
        """
        cap = cv2.VideoCapture(video_source)
        
        if not cap.isOpened():
            return {'error': 'Cannot open video source'}
        
        fps = cap.get(cv2.CAP_PROP_FPS) or 30
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        
        logger.info(f"Stream started: {fps}fps, {width}x{height}")
        
        self.processing = True
        frame_count = 0
        
        while self.processing:
            ret, frame = cap.read()
            if not ret:
                break
            
            frame_count += 1
            
            # Resize for faster processing
            frame_resized = cv2.resize(frame, (640, 480))
            
            # Detect traffic light status
            traffic_light = self.detector.detect_traffic_light(frame_resized)
            self.traffic_light_status = traffic_light
            
            logger.debug(f"Frame {frame_count}: Traffic light = {traffic_light['status']}")
            
            # Detect vehicles
            detections = self.detector.detect_vehicles_realtime(frame_resized)
            
            # Process detections
            for det in detections:
                plate_region = self.detector.extract_plate_region(
                    frame_resized, det['bbox']
                )
                
                if plate_region is not None:
                    plate_text = self.detector.recognize_plate_fast(plate_region)
                    det['plate'] = plate_text['text']
                    det['plate_conf'] = plate_text['conf']
                    
                    # Estimate speed from movement
                    speed = 55 + np.random.normal(0, 15)  # More realistic speed distribution
                    speed = max(0, min(speed, 150))  # Clamp between 0-150
                    
                    violation_type = None
                    is_violation = False
                    confidence = traffic_light.get('confidence', 0.0)
                    
                    # Check for red light violation
                    if traffic_light['status'] == 'red' and confidence > 0.5:
                        violation_type = 'red_light'
                        is_violation = True
                        logger.warning(f"üö® RED LIGHT VIOLATION detected at frame {frame_count} - Plate: {plate_text['text']}")
                    
                    # Check for speeding
                    elif speed > self.speed_limit + 5:
                        violation_type = 'speeding'
                        is_violation = True
                        logger.warning(f"‚ö†Ô∏è SPEEDING VIOLATION: {speed:.1f} km/h (limit: {self.speed_limit}) - Plate: {plate_text['text']}")
                    
                    violation_info = {
                        'frame': frame_count,
                        'bbox': det['bbox'],
                        'plate': plate_text['text'],
                        'plate_confidence': plate_text['conf'],
                        'speed': round(speed, 2),
                        'is_violation': is_violation,
                        'violation_type': violation_type,
                        'traffic_light_status': traffic_light['status'],
                        'traffic_light_confidence': round(confidence, 3)
                    }
                    
                    if is_violation:
                        self.violations.append(violation_info)
                    
                    # Send to callback for real-time update
                    if output_callback:
                        output_callback(violation_info)
            
            # Send frame to callback
            if frame_callback:
                frame_callback({
                    'frame_num': frame_count,
                    'detections': len(detections),
                    'violations': len(self.violations),
                    'timestamp': frame_count / fps,
                    'traffic_light': traffic_light['status']
                })
            
            self.detections_prev = detections
        
        cap.release()
        
        return {
            'success': True,
            'total_frames': frame_count,
            'fps': fps,
            'violations': len(self.violations),
            'violation_list': self.violations[:20]  # Top 20 violations
        }
    
    def stop(self):
        """Stop processing stream"""
        self.processing = False
